{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: speechrecognition in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (3.10.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from speechrecognition) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from speechrecognition) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (2024.6.2)\n",
      "Requirement already satisfied: pyttsx3 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (2.90)\n",
      "Requirement already satisfied: comtypes in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from pyttsx3) (1.4.4)\n",
      "Requirement already satisfied: pypiwin32 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from pyttsx3) (306)\n",
      "Requirement already satisfied: neuralintents in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: numpy in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from neuralintents) (1.26.4)\n",
      "Requirement already satisfied: nltk in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from neuralintents) (3.8.1)\n",
      "Requirement already satisfied: tensorflow in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from neuralintents) (2.16.1)\n",
      "Requirement already satisfied: click in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from nltk->neuralintents) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from nltk->neuralintents) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from nltk->neuralintents) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from nltk->neuralintents) (4.66.4)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow->neuralintents) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (3.3.0)\n",
      "Requirement already satisfied: packaging in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (2.32.3)\n",
      "Requirement already satisfied: setuptools in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (57.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow->neuralintents) (0.31.0)\n",
      "Requirement already satisfied: colorama in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from click->nltk->neuralintents) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow->neuralintents) (0.43.0)\n",
      "Requirement already satisfied: rich in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow->neuralintents) (13.7.1)\n",
      "Requirement already satisfied: namex in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow->neuralintents) (0.0.8)\n",
      "Requirement already satisfied: optree in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow->neuralintents) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow->neuralintents) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow->neuralintents) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow->neuralintents) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow->neuralintents) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow->neuralintents) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow->neuralintents) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow->neuralintents) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow->neuralintents) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow->neuralintents) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow->neuralintents) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\ai projects\\voice-assistant\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow->neuralintents) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install speechrecognition\n",
    "!pip install pyttsx3\n",
    "!pip install neuralintents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralintents import GenericAssistant\n",
    "import speech_recognition as sr\n",
    "import pyttsx3 as tts\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "speaker = tts.init()\n",
    "speaker.setProperty('rate', 150)\n",
    "\n",
    "todo_list = ['Go shopping', 'Clean the house', 'Cook dinner']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_note():\n",
    "    global recognizer\n",
    "    global speaker\n",
    "\n",
    "    speaker.say('What do you want to write onto your note?')\n",
    "    speaker.runAndWait()\n",
    "\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        try:\n",
    "            with sr.Microphone() as mic:\n",
    "                recognizer.adjust_for_ambient_noise(mic, duration=0.2)\n",
    "                audio = recognizer.listen(mic)\n",
    "                note = recognizer.recognize_google(audio)\n",
    "                note = note.lower()\n",
    "\n",
    "                speaker.say('Choose a filename')\n",
    "                speaker.runAndWait()\n",
    "\n",
    "                audio = recognizer.listen(mic)\n",
    "                filename = recognizer.recognize_google(audio)\n",
    "                filename = filename.lower()\n",
    "\n",
    "            with open(f\"{filename}.txt\", 'w') as f:\n",
    "                f.write(note)\n",
    "                done = True\n",
    "                speaker.say('I successfully created the note {filename} with the following content: {note}')\n",
    "                speaker.runAndWait()\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "            recognizer = sr.Recognizer()\n",
    "            speaker.say('I did not understand you! Please try again!')\n",
    "            speaker.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_todo():\n",
    "    global recognizer\n",
    "    global speaker\n",
    "\n",
    "    speaker.say('What do you want to add?')\n",
    "    speaker.runAndWait()\n",
    "\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        try:\n",
    "            with sr.Microphone() as mic:\n",
    "                recognizer.adjust_for_ambient_noise(mic, duration=0.2)\n",
    "                audio = recognizer.listen(mic)\n",
    "                item = recognizer.recognize_google(audio)\n",
    "                item = item.lower()\n",
    "\n",
    "                todo_list.append(item)\n",
    "                done = True\n",
    "\n",
    "                speaker.say(f'I added {item} to the to do list!')\n",
    "                speaker.runAndWait()\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "            recognizer = sr.Recognizer()\n",
    "            speaker.say('I did not understand you! Please try again!')\n",
    "            speaker.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_todos():\n",
    "    global speaker\n",
    "\n",
    "    speaker.say('The items on your to do list are the following:')\n",
    "    for item in todo_list:\n",
    "        speaker.say(item)\n",
    "    speaker.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello():\n",
    "    global speaker\n",
    "\n",
    "    speaker.say('Hello! How can I help you today?')\n",
    "    speaker.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quit():\n",
    "    global speaker\n",
    "    speaker.say(\"Goodbye\")\n",
    "    speaker.runAndWait()\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {\n",
    "    \"greeting\": hello,\n",
    "    \"create_note\": create_note,\n",
    "    \"add_todo\": add_todo,\n",
    "    \"show_todos\": show_todos,\n",
    "    \"exit\": quit\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BasicAssistant' object has no attribute 'add_custom_handler'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m assistant \u001b[38;5;241m=\u001b[39m BasicAssistant(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintents.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m intent, method \u001b[38;5;129;01min\u001b[39;00m mappings\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 4\u001b[0m     \u001b[43massistant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_custom_handler\u001b[49m(intent, method)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BasicAssistant' object has no attribute 'add_custom_handler'"
     ]
    }
   ],
   "source": [
    "assistant = GenericAssistant('intents.json',intent_methods=mappings)\n",
    "\n",
    "assistant.train_model()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        with sr.Microphone() as mic:\n",
    "            recognizer.adjust_for_ambient_noise(mic, duration=0.2)\n",
    "            audio = recognizer.listen(mic)\n",
    "            message = recognizer.recognize_google(audio)\n",
    "            message = message.lower()\n",
    "\n",
    "        assistant.request(message)\n",
    "    except sr.UnknownValueError:\n",
    "        recognizer = sr.Recognizer()\n",
    "    except sr.RequestError:\n",
    "        recognizer = sr.Recognizer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
